{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96026572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eb83e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50542, 1696)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned and joined data\n",
    "processed_df = pd.read_csv('bin/cleaned_and_joined.csv')\n",
    "processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8adf097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the labels of each variable into a dictionary\n",
    "# # https://www.fhfa.gov/sites/default/files/2024-06/nsmo_v50_labels.sas\n",
    "\n",
    "# with open('variable_labels.yaml', 'r', encoding='utf-8') as file:\n",
    "#     variable_labels_dict = yaml.safe_load(file)\n",
    "\n",
    "# # Load the the format of each variable into a dictionary\n",
    "# # https://www.fhfa.gov/sites/default/files/2024-06/nsmo_v50_labels.sas\n",
    "\n",
    "# with open('variable_formats.yaml', 'r', encoding='utf-8') as file:\n",
    "#     variable_formats_dict = yaml.safe_load(file)\n",
    "\n",
    "# # Load the categories for every categorical variable (exclude null categories) into a dictionary\n",
    "# # https://www.fhfa.gov/sites/default/files/2024-06/nsmo_v50_formats.sas\n",
    "\n",
    "# with open('categorical_variables_categories.yaml', 'r', encoding='utf-8') as file:\n",
    "#     categorical_variables_categories_dict = yaml.safe_load(file)\n",
    "\n",
    "# # Create a set of all variable formats\n",
    "\n",
    "# variable_formats_set = set(variable_formats_dict.values())\n",
    "\n",
    "# # Create a list of the categorical variables and a list of the numeric variables\n",
    "\n",
    "# categorical_variables = []\n",
    "# numeric_variables = []\n",
    "\n",
    "# categorical_variable_formats = set(categorical_variables_categories_dict.keys())\n",
    "# numeric_variable_formats = variable_formats_set - categorical_variable_formats\n",
    "\n",
    "# for col in processed_df.columns:\n",
    "#     if variable_formats_dict[col] in categorical_variable_formats:\n",
    "#         categorical_variables.append(col)\n",
    "#     elif variable_formats_dict[col] in numeric_variable_formats:\n",
    "#         numeric_variables.append(col) \n",
    "#     else:\n",
    "#         print(\"Error in bifurcation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97d80deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'Beta_winsorized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b471f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List variables to be excluded\n",
    "\n",
    "exclude_variables = ['nsmoid',          # NSMO Identification Number\n",
    "                     'survey_wave',     # NSMO Survey Wave (Quarterly)\n",
    "                     'analysis_weight', # NSMO Analysis Weight (Sampling Weight x Non-response Adjustment)\n",
    "                     'rate_spread',     # Mortgage Interest Rate Spread at Origination (Percent)\n",
    "                     'pmms',            # Freddie Mac's Primary Mortgage Market Survey (PMMS) Rate at Origination (Percent)\n",
    "                     'DGS30',           # Market Yield on U.S. Treasury Securities at 30-Year Constant Maturity, Quoted on an Investment Basis\n",
    "                     'Beta'             # Original Beta before it was winsorized\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c916d13",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numeric_variables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Append the new numeric variables to the list of all numeric variables\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mnumeric_variables\u001b[49m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDGS30\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m numeric_variables\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBeta\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m numeric_variables\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBeta_winsorized\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numeric_variables' is not defined"
     ]
    }
   ],
   "source": [
    "# Append the new numeric variables to the list of all numeric variables\n",
    "\n",
    "numeric_variables.append('DGS30')\n",
    "numeric_variables.append('Beta')\n",
    "numeric_variables.append('Beta_winsorized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98153ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a complete list of all excluded variables and exclude them from the list of numeric variables\n",
    "# Updated this cell from the previous workbook to utilize the new cleaned and joined dataset\n",
    "\n",
    "list_of_excluded_variables = list([target_variable]) + exclude_variables\n",
    "print(\"Excluded variables:\", list_of_excluded_variables)\n",
    "print(\"Numeric variables before exclusion:\", numeric_variables)\n",
    "\n",
    "# Filter out excluded variables using list comprehension\n",
    "numeric_variables = [var for var in numeric_variables if var not in list_of_excluded_variables]\n",
    "\n",
    "print(\"Numeric variables after exclusion:\", numeric_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1699e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of missing values in the target variable\n",
    "\n",
    "sum_of_missing_values_in_target = processed_df[target_variable].isna().sum()\n",
    "print(\"sum of missing values in target: \", sum_of_missing_values_in_target, \n",
    "      \"\\ntotal observations in data: \", processed_df.shape[0], \n",
    "      \"\\npercentage of target with missing values: \", round(sum_of_missing_values_in_target / processed_df.shape[0] * 100,1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad44db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop observations in the data where the target variable has missing values\n",
    "\n",
    "processed_df = processed_df.dropna(subset=target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b923d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregate the predictor variables from the target variable\n",
    "\n",
    "X = processed_df.drop(columns=list_of_excluded_variables)\n",
    "y = processed_df[target_variable]\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb22dbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing partitions\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, random_state=0)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc09c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional debugging to understand the data\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_train columns: {X_train.columns.tolist()}\")\n",
    "print(f\"X_train dtypes:\\n{X_train.dtypes}\")\n",
    "\n",
    "# Check what variables were excluded\n",
    "print(f\"\\nTarget variable: {target_variable}\")\n",
    "print(f\"Exclude variables: {exclude_variables}\")\n",
    "print(f\"List of excluded variables: {list_of_excluded_variables}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080708d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values for the numeric variables using the mean values\n",
    "\n",
    "# Instantiate an imputer object\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "print(len(numeric_variables))\n",
    "\n",
    "# Prevent \"data leakage\" by fitting the imputer on just the training data, and then apply it to the holdout testing data\n",
    "# imputer.fit(X_train[numeric_variables])\n",
    "# print(f\"Imputer fitted for {len(numeric_variables)} numeric variables\")\n",
    "\n",
    "# # Transform both the training and testing data using the imputer fitted on just the training data\n",
    "# X_train[numeric_variables] = imputer.transform(X_train[numeric_variables])\n",
    "# X_test[numeric_variables] = imputer.transform(X_test[numeric_variables])\n",
    "\n",
    "# print(f\"Imputation completed for {len(numeric_variables)} numeric variables\")\n",
    "# print(f\"X_train shape: {X_train.shape}\")\n",
    "# print(f\"X_test shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a904db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale values for the numeric variables\n",
    "\n",
    "# Instantiate a scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Prevent \"data leakage\" by fitting the scaler on just the imputed training data, and then apply it to the holdout testing data\n",
    "scaler.fit(X_train[numeric_variables])\n",
    "\n",
    "# Scale both the training data and testing data using the scaler fitted on just the training data\n",
    "X_train[numeric_variables] = scaler.transform(X_train[numeric_variables])\n",
    "X_test[numeric_variables] = scaler.transform(X_test[numeric_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b16bad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mads_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
